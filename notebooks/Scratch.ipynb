{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f7a5701-f7cc-445c-b4f7-fe886023e2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import scipy.cluster\n",
    "from xgboost import XGBRegressor\n",
    "import numpy as np\n",
    "import shap\n",
    "\n",
    "seed = 2023\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b26ac78c-bbd2-4734-b4e3-f0eb4f5bacfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = shap.datasets.california()\n",
    "model = XGBRegressor(n_estimators=100, subsample=0.3)\n",
    "model.fit(X, y)\n",
    "\n",
    "instance = X[0:1]\n",
    "references = X[1:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41656ebc-c564-4c0a-b643-f46567027d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "partition_clustering = shap.utils.partition_tree(X)\n",
    "plt.figure(figsize=(15, 6))\n",
    "sp.cluster.hierarchy.dendrogram(partition_clustering , labels=X.columns)\n",
    "plt.title(\"Hierarchical Clustering Dendrogram\")\n",
    "plt.xlabel(\"feature\")\n",
    "plt.ylabel(\"distance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79e6b9e8-02bd-4446-8838-f911f2675c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_hierarchy = {\n",
    "    'cluster_12': {\n",
    "        'cluster_11': {\n",
    "            'AveOccup': 'AveOccup',\n",
    "            'MedInc': 'MedInc'\n",
    "        },\n",
    "        'cluster_9': {\n",
    "            'Longitude': 'Longitude',\n",
    "            'Population': 'Population'\n",
    "        }\n",
    "    },\n",
    "    'cluster_13': {\n",
    "        'HouseAge': 'HouseAge',\n",
    "        'cluster_10': {\n",
    "            'Latitude': 'Latitude',\n",
    "            'cluster_8': {\n",
    "                'AveBedrms': 'AveBedrms',\n",
    "                'AveRooms': 'AveRooms'\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d9a5af27-c81e-40a6-b937-a38ca284d9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue  # multi-producer, multi-consumer queues\n",
    "import time  # time execution\n",
    "\n",
    "import numpy as np  # numpy base\n",
    "from numba import njit  # just in time compiler\n",
    "from tqdm.auto import tqdm  # progress bar\n",
    "\n",
    "from shap import Explanation, links  # shap modules\n",
    "from shap.explainers._explainer import Explainer\n",
    "from shap.models import Model\n",
    "from shap.utils import MaskedModel, OpChain, make_masks, safe_isinstance\n",
    "from itertools import chain, combinations, product\n",
    "\n",
    "class PartitionExplainer2(Explainer):\n",
    "    \"\"\"Uses the Partition SHAP method to explain the output of any function.\n",
    "    The method has two options:\n",
    "    1. The Cluster method. Users can pass or call a scipy hierarchy of the features using any distance measure.\n",
    "    2. The custom Partition method. Users can pass any nested dictionaries of the feature coalitions.\n",
    "\n",
    "    Partition SHAP computes Shapley values recursively through a hierarchy of features, this\n",
    "    hierarchy defines feature coalitions and results in the Winter values from game theory.\n",
    "\n",
    "    The Cluster method has two particularly nice properties:\n",
    "\n",
    "    1) PartitionExplainer is model-agnostic but when using a balanced partition tree only has\n",
    "       quadratic exact runtime (in term of the number of input features). This is in contrast to the\n",
    "       exponential exact runtime of KernelExplainer or SamplingExplainer.\n",
    "    2) PartitionExplainer always assigns to groups of correlated features the credit that set of features\n",
    "       would have had if treated as a group. This means if the hierarchical clustering given to\n",
    "       PartitionExplainer groups correlated features together, then feature correlations are\n",
    "       \"accounted for\" in the sense that the total credit assigned to a group of tightly dependent features\n",
    "       does not depend on how they behave if their correlation structure was broken during the explanation's\n",
    "       perturbation process.\n",
    "    Note that for linear models the Winter values that PartitionExplainer returns are the same as the standard\n",
    "    non-hierarchical Shapley values.\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        masker,\n",
    "        *,\n",
    "        output_names=None,\n",
    "        link=links.identity,\n",
    "        linearize_link=True,\n",
    "        feature_names=None,\n",
    "        partition_tree=None,\n",
    "        **call_args,\n",
    "    ):\n",
    "        \"\"\"Build a PartitionExplainer for the given model with the given masker.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        model : function\n",
    "            User supplied function that takes a matrix of samples (# samples x # features) and\n",
    "            computes the output of the model for those samples.\n",
    "\n",
    "        masker : function or numpy.array or pandas.DataFrame or tokenizer\n",
    "            The function used to \"mask\" out hidden features of the form `masker(mask, x)`. It takes a\n",
    "            single input sample and a binary mask and returns a matrix of masked samples. These\n",
    "            masked samples will then be evaluated using the model function and the outputs averaged.\n",
    "            As a shortcut for the standard masking using by SHAP you can pass a background data matrix\n",
    "            instead of a function and that matrix will be used for masking. Domain specific masking\n",
    "            functions are available in shap such as shap.maksers.Image for images and shap.maskers.Text\n",
    "            for text.\n",
    "\n",
    "        partition_tree : Nested dictionary of features  ################################ NOT CURRENTLY IMPLEMENTED #####################################\n",
    "            A hierarchical clustering of the input features represented by a matrix that follows the format\n",
    "            used by scipy.cluster.hierarchy (see the notebooks_html/partition_explainer directory an example).\n",
    "            If this is a function then the function produces a clustering matrix when given a single input\n",
    "            example. If you are using a standard SHAP masker object then you can pass masker.clustering\n",
    "            to use that masker's built-in clustering of the features, or if partition_tree is None then\n",
    "            masker.clustering will be used by default.\n",
    "\n",
    "        Examples\n",
    "        --------\n",
    "        See `Partition explainer examples <https://shap.readthedocs.io/en/latest/api_examples/explainers/PartitionExplainer.html>`_\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            model,\n",
    "            masker,\n",
    "            link=link,\n",
    "            linearize_link=linearize_link,\n",
    "            algorithm=\"partition\",\n",
    "            output_names=output_names,\n",
    "            feature_names=feature_names,\n",
    "        )\n",
    "\n",
    "        # convert dataframes\n",
    "        # if isinstance(masker, pd.DataFrame):\n",
    "        #     masker = TabularMasker(masker)\n",
    "        # elif isinstance(masker, np.ndarray) and len(masker.shape) == 2:\n",
    "        #     masker = TabularMasker(masker)\n",
    "        # elif safe_isinstance(masker, \"transformers.PreTrainedTokenizer\"):\n",
    "        #     masker = TextMasker(masker)\n",
    "        # self.masker = masker\n",
    "\n",
    "        # TODO: maybe? if we have a tabular masker then we build a PermutationExplainer that we\n",
    "        # will use for sampling\n",
    "        self.input_shape = (\n",
    "            masker.shape[1:]\n",
    "            if hasattr(masker, \"shape\") and not callable(masker.shape)\n",
    "            else None\n",
    "        )\n",
    "        # self.output_names = output_names\n",
    "        if not safe_isinstance(self.model, \"shap.models.Model\"):\n",
    "            self.model = Model(self.model)  # lambda *args: np.array(model(*args))\n",
    "        self.expected_value = None\n",
    "        self._curr_base_value = None\n",
    "\n",
    "        # handle higher dimensional tensor inputs\n",
    "        if self.input_shape is not None and len(self.input_shape) > 1:\n",
    "            self._reshaped_model = lambda x: self.model(\n",
    "                x.reshape(x.shape[0], *self.input_shape)\n",
    "            )\n",
    "        else:\n",
    "            self._reshaped_model = self.model\n",
    "\n",
    "        self.partition_tree = partition_tree\n",
    "        if partition_tree is not None:\n",
    "\n",
    "            self.root = Node(\"Root\")\n",
    "            build_tree(partition_tree, self.root)\n",
    "            self.combinations_list = generate_paths_and_combinations(self.root)\n",
    "            self.masks, self.keys = create_masks1(self.root, self.masker.feature_names)\n",
    "            self.masks_dict = dict(zip(self.keys, self.masks))\n",
    "            self.unique_masks = create_combined_masks(self.combinations_list, self.masks_dict)\n",
    "            self.unique_masks_list = [mask for _, mask in self.unique_masks]\n",
    "            self.unique_masks_set = set(map(tuple, self.unique_masks_list))\n",
    "            self.unique_masks = [np.array(mask) for mask in self.unique_masks_set]\n",
    "            self._clustering = None  # Ensure _clustering is None when using partition_tree\n",
    "        else:\n",
    "            if not hasattr(masker, \"clustering\"):\n",
    "                raise ValueError(\n",
    "                    \"The passed masker does not have masker.clustering, so the partition_tree must be passed!\"\n",
    "                )\n",
    "            self._clustering = masker.clustering\n",
    "            if not callable(masker.clustering):\n",
    "                self._mask_matrix = make_masks(self._clustering)\n",
    "\n",
    "        # if getattr(self.masker, \"clustering\", None) is None:\n",
    "        #     raise ValueError(\n",
    "        #         \"The passed masker must have a .clustering attribute defined! Try shap.maskers.Partition(data) for example.\"\n",
    "        #     )\n",
    "\n",
    "        # if partition_tree is None:\n",
    "        #     if not hasattr(masker, \"partition_tree\"):\n",
    "        #         raise ValueError(\n",
    "        #             \"The passed masker does not have masker.clustering, so the partition_tree must be passed!\"\n",
    "        #         )\n",
    "        #     self.partition_tree = masker.clustering\n",
    "        # else:\n",
    "        #     self.partition_tree = partition_tree\n",
    "        # if we don't have a dynamic clustering algorithm then can precowe mpute\n",
    "        # a lot of information\n",
    "        # if not callable(self.masker.clustering):\n",
    "        #     self._clustering = self.masker.clustering  #\n",
    "        #     self._mask_matrix = make_masks(self._clustering)  # make masks argument\n",
    "\n",
    "        # if we have gotten default arguments for the call function we need to wrap ourselves in a new class that\n",
    "        # has a call function with those new default arguments\n",
    "        if len(call_args) > 0:\n",
    "\n",
    "            class PartitionExplainer(self.__class__):\n",
    "                # this signature should match the __call__ signature of the class defined below\n",
    "                def __call__(\n",
    "                    self,\n",
    "                    *args,\n",
    "                    max_evals=500,\n",
    "                    fixed_context=None,\n",
    "                    main_effects=False,\n",
    "                    error_bounds=False,\n",
    "                    batch_size=\"auto\",\n",
    "                    outputs=None,\n",
    "                    silent=False,\n",
    "                ):\n",
    "                    return super().__call__(\n",
    "                        *args,\n",
    "                        max_evals=max_evals,\n",
    "                        fixed_context=fixed_context,\n",
    "                        main_effects=main_effects,\n",
    "                        error_bounds=error_bounds,\n",
    "                        batch_size=batch_size,\n",
    "                        outputs=outputs,\n",
    "                        silent=silent,\n",
    "                    )\n",
    "\n",
    "            PartitionExplainer.__call__.__doc__ = self.__class__.__call__.__doc__\n",
    "            self.__class__ = PartitionExplainer\n",
    "            for k, v in call_args.items():\n",
    "                self.__call__.__kwdefaults__[k] = v\n",
    "\n",
    "    # note that changes to this function signature should be copied to the default call argument wrapper above\n",
    "    def __call__(\n",
    "        self,\n",
    "        *args,\n",
    "        max_evals=500,\n",
    "        fixed_context=None,\n",
    "        main_effects=False,\n",
    "        error_bounds=False,\n",
    "        batch_size=\"auto\",\n",
    "        outputs=None,\n",
    "        silent=False,\n",
    "    ):\n",
    "        \"\"\"Explain the output of the model on the given arguments.\"\"\"\n",
    "        return super().__call__(\n",
    "            *args,\n",
    "            max_evals=max_evals,\n",
    "            fixed_context=fixed_context,\n",
    "            main_effects=main_effects,\n",
    "            error_bounds=error_bounds,\n",
    "            batch_size=batch_size,\n",
    "            outputs=outputs,\n",
    "            silent=silent,\n",
    "        )\n",
    "\n",
    "    def explain_row(\n",
    "        self,\n",
    "        *row_args,\n",
    "        max_evals,\n",
    "        main_effects,\n",
    "        error_bounds,\n",
    "        batch_size,\n",
    "        outputs,\n",
    "        silent,\n",
    "        fixed_context=\"auto\",\n",
    "    ):\n",
    "        if fixed_context == \"auto\":\n",
    "            fixed_context = None\n",
    "        elif fixed_context not in [0, 1, None]:\n",
    "            raise ValueError(\n",
    "                \"Unknown fixed_context value passed (must be 0, 1 or None): %s\"\n",
    "                % fixed_context\n",
    "            )\n",
    "\n",
    "        fm = MaskedModel(\n",
    "            self.model, self.masker, self.link, self.linearize_link, *row_args\n",
    "        )\n",
    "        M = len(fm)\n",
    "        m00 = np.zeros(M, dtype=bool)\n",
    "        if self._curr_base_value is None or not getattr(\n",
    "            self.masker, \"fixed_background\", False\n",
    "        ):\n",
    "            self._curr_base_value = fm(m00.reshape(1, -1), zero_index=0)[0]\n",
    "        f11 = fm(~m00.reshape(1, -1))[0]\n",
    "\n",
    "        if self.partition_tree is not None:\n",
    "            return self.explain_with_partition_tree(fm, self._curr_base_value, f11, max_evals, outputs, fixed_context, batch_size, silent)\n",
    "        else:\n",
    "            return self.explain_with_clustering(fm, self._curr_base_value, f11, max_evals, outputs, fixed_context, batch_size, silent)\n",
    "\n",
    "    def explain_with_clustering(\n",
    "        self, fm, f00, f11, max_evals, outputs, fixed_context, batch_size, silent\n",
    "    ):\n",
    "        if callable(self.masker.clustering):\n",
    "            self._clustering = self.masker.clustering(*row_args)\n",
    "            self._mask_matrix = make_masks(self._clustering)\n",
    "        M = len(fm)\n",
    "        m00 = np.zeros(M, dtype=bool)\n",
    "        if (\n",
    "            hasattr(self._curr_base_value, \"shape\")\n",
    "            and len(self._curr_base_value.shape) > 0\n",
    "        ):\n",
    "            if outputs is None:\n",
    "                outputs = np.arange(len(self._curr_base_value))\n",
    "            elif isinstance(outputs, OpChain):\n",
    "                outputs = outputs.apply(Explanation(f11)).values\n",
    "\n",
    "            out_shape = (2 * self._clustering.shape[0] + 1, len(outputs))\n",
    "        else:\n",
    "            out_shape = (2 * self._clustering.shape[0] + 1,)\n",
    "\n",
    "        if max_evals == \"auto\":\n",
    "            max_evals = 500\n",
    "\n",
    "        self.values = np.zeros(out_shape)\n",
    "        self.dvalues = np.zeros(out_shape)\n",
    "\n",
    "        self.owen(\n",
    "            fm,\n",
    "            self._curr_base_value,\n",
    "            f11,\n",
    "            max_evals - 2,\n",
    "            outputs,\n",
    "            fixed_context,\n",
    "            batch_size,\n",
    "            silent,\n",
    "        )\n",
    "        self.values[:] = self.dvalues  # Assign dvalues to values\n",
    "        lower_credit(len(self.dvalues) - 1, 0, M, self.values, self._clustering)\n",
    "        return {\n",
    "            \"values\": self.values[:M].copy(),\n",
    "            \"expected_values\": self._curr_base_value\n",
    "            if outputs is None\n",
    "            else self._curr_base_value[outputs],\n",
    "            \"mask_shapes\": [s + out_shape[1:] for s in fm.mask_shapes],\n",
    "            \"main_effects\": None,\n",
    "            \"hierarchical_values\": self.dvalues.copy(),\n",
    "            \"clustering\": self._clustering,\n",
    "            \"output_indices\": outputs,\n",
    "            \"output_names\": getattr(self.model, \"output_names\", None),\n",
    "        }\n",
    "\n",
    "    def explain_with_partition_tree(\n",
    "        self, fm, f00, f11, max_evals, outputs, fixed_context, batch_size, silent\n",
    "    ):\n",
    "        # Step 1: Generate all unique masks\n",
    "        self.root = Node(\"Root\")\n",
    "        build_tree(self.partition_tree, self.root)\n",
    "        self.combinations_list = generate_paths_and_combinations(self.root)\n",
    "        self.masks, self.keys = create_masks1(self.root, self.masker.feature_names)\n",
    "        self.masks_dict = dict(zip(self.keys, self.masks))\n",
    "        self.mask_permutations = create_combined_masks(self.combinations_list, self.masks_dict)\n",
    "        self.masks_list = [mask for _, mask in self.mask_permutations]\n",
    "        self.unique_masks_set = set(map(tuple, self.masks_list))\n",
    "        self.unique_masks = [np.array(mask) for mask in self.unique_masks_set]\n",
    "\n",
    "        # Step 2: Compute model results for all unique masks\n",
    "        mask_results = {}\n",
    "        for mask in self.unique_masks:\n",
    "            print(mask)\n",
    "            result = fm(mask.reshape(1, -1))\n",
    "            print(\"model results\", result)\n",
    "            mask_results[tuple(mask)] = result\n",
    "\n",
    "        # Step 3: Compute marginals for permutations\n",
    "        shap_values = np.zeros(len(fm))\n",
    "        last_key_to_off_indexes, last_key_to_on_indexes = map_combinations_to_unique_masks(\n",
    "            self.mask_permutations, self.unique_masks\n",
    "            )\n",
    "\n",
    "        feature_name_to_index = {name: idx for idx, name in enumerate(self.masker.feature_names)}\n",
    "        print(feature_name_to_index)\n",
    "\n",
    "        for last_key in last_key_to_off_indexes:\n",
    "            off_indexes = last_key_to_off_indexes[last_key]\n",
    "            on_indexes = last_key_to_on_indexes[last_key]\n",
    "            num_permutations = len(off_indexes)\n",
    "\n",
    "            for off_index, on_index in zip(off_indexes, on_indexes):\n",
    "                off_result = mask_results[tuple(self.unique_masks[off_index])]\n",
    "                on_result = mask_results[tuple(self.unique_masks[on_index])]\n",
    "\n",
    "                print(\"off\", off_index, off_result,\"on\", on_index, on_result, num_permutations)\n",
    "                print(\"the values\", (on_result - off_result) / num_permutations)\n",
    "                marginal_contribution = (on_result - off_result) /num_permutations\n",
    "                print(\"the marginal\", marginal_contribution)\n",
    "                shap_values[feature_name_to_index[last_key]] += marginal_contribution.item()\n",
    "        # Step 4: Return results\n",
    "        return {\n",
    "            \"values\": shap_values,\n",
    "            \"expected_values\": f00,\n",
    "            \"mask_shapes\": [s + (len(fm.mask_shapes[0]),) for s in fm.mask_shapes],\n",
    "            \"main_effects\": None,\n",
    "            \"hierarchical_values\": shap_values,\n",
    "            \"clustering\": None,\n",
    "            \"output_indices\": outputs,\n",
    "            \"output_names\": getattr(self.model, \"output_names\", None),\n",
    "        }\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"shap.explainers.PartitionExplainer()\"\n",
    "\n",
    "    ################\n",
    "    # owen3 has a more efficient strategy dynamically adjusting the context and the number of evaluations\n",
    "    # I removed it for now to understand the method\n",
    "    ###############\n",
    "\n",
    "    ###################### MAIN FUNCTION THAT CALCULATES THE WINTER VALUES #####################\n",
    "\n",
    "    def owen(\n",
    "        self, fm, f00, f11, max_evals, output_indexes, fixed_context, batch_size, silent\n",
    "    ):\n",
    "        \"\"\"Compute a nested set of recursive Owen values based on an ordering recursion.\"\"\"\n",
    "        # f = self._reshaped_model\n",
    "        # r = self.masker\n",
    "        # masks = np.zeros(2*len(inds)+1, dtype=int)\n",
    "        M = len(fm)  # number of features\n",
    "        m00 = np.zeros(\n",
    "            M, dtype=bool\n",
    "        )  # all false mask       #f00 = fm(m00.reshape(1,-1))[0] = fm(m00.reshape(1, -1), zero_index=0)[0]\n",
    "        base_value = f00  # baseline value calculated outside assigneed here only used in the output??????\n",
    "        # f11 = fm(~m00.reshape(1,-1))[0]\n",
    "        # f11 = self._reshaped_model(r(~m00, x)).mean(0)\n",
    "        ind = len(self.dvalues) - 1  # index the length of the hierarchy\n",
    "        #print(\"ind\", ind)\n",
    "\n",
    "        # make sure output_indexes is a list of indexes\n",
    "        if output_indexes is not None:\n",
    "            # assert self.multi_output, \"output_indexes is only valid for multi-output models!\"\n",
    "            # inds = output_indexes.apply(f11, 0)\n",
    "            # out_len = output_indexes_len(output_indexes)\n",
    "            # if output_indexes.startswith(\"max(\"):\n",
    "            #     output_indexes = np.argsort(-f11)[:out_len]\n",
    "            # elif output_indexes.startswith(\"min(\"):\n",
    "            #     output_indexes = np.argsort(f11)[:out_len]\n",
    "            # elif output_indexes.startswith(\"max(abs(\"):\n",
    "            #     output_indexes = np.argsort(np.abs(f11))[:out_len]\n",
    "            # print(output_indexes) # for this one is none\n",
    "\n",
    "            f00 = f00[output_indexes]\n",
    "            f11 = f11[output_indexes]\n",
    "\n",
    "        q = queue.PriorityQueue()  # setting up priority que\n",
    "        q.put(\n",
    "            (0, 0, (m00, f00, f11, ind, 1.0))\n",
    "        )  # the things in the cue are the all false array, all false value, all true value, length of hierarchy, weight used for the division??\n",
    "        eval_count = 0  # starting at 0\n",
    "        total_evals = min(\n",
    "            max_evals, (M - 1) * M\n",
    "        )  # TODO: (M-1)*M is only right for balanced clusterings, but this is just for plotting progress...\n",
    "        pbar = None  # progress bar\n",
    "        start_time = time.time()  # measure time\n",
    "        while not q.empty():  #################### go throught the whole que ##############################\n",
    "            # if we passed our execution limit then leave everything else on the internal nodes\n",
    "            if eval_count >= max_evals:\n",
    "                #print(\"we are doing this\")\n",
    "                while not q.empty():\n",
    "                    m00, f00, f11, ind, weight = q.get()[2]\n",
    "                    self.dvalues[ind] += (f11 - f00) * weight\n",
    "                break\n",
    "\n",
    "            # create a batch of work to do\n",
    "            batch_args = []\n",
    "            batch_masks = []  # batch size is 10 at auto\n",
    "\n",
    "            # this bit creates the entire list of masks needed recursively\n",
    "            while (\n",
    "                not q.empty()\n",
    "                and len(batch_masks) < batch_size\n",
    "                and eval_count + len(batch_masks) < max_evals\n",
    "            ):\n",
    "                # work until q is not empty or other stop criterion are triggered\n",
    "\n",
    "                # get our next set of arguments\n",
    "                m00, f00, f11, ind, weight = q.get()[2]\n",
    "\n",
    "                # get the left and right children of this cluster\n",
    "                # print(ind, M)\n",
    "                lind = int(self._clustering[ind - M, 0]) if ind >= M else -1\n",
    "                rind = int(self._clustering[ind - M, 1]) if ind >= M else -1\n",
    "\n",
    "                # get the distance of this cluster's children\n",
    "                if ind < M:\n",
    "                    distance = -1\n",
    "                else:\n",
    "                    if self._clustering.shape[1] >= 3:\n",
    "                        distance = self._clustering[ind - M, 2]\n",
    "                    else:\n",
    "                        distance = 1\n",
    "\n",
    "                # check if we are a leaf node (or other negative distance cluster) and so should terminate our decent\n",
    "\n",
    "                # here we assign self.dvalues by adding the current marginal ##########################\n",
    "                # it is conditional on the clustering distance\n",
    "                if distance < 0:\n",
    "                    # print(\"the marginals\", (f11 - f00) * weight)\n",
    "                    self.dvalues[ind] += (f11 - f00) * weight\n",
    "                    # print(\"updated values\", self.dvalues, ind)\n",
    "                    continue\n",
    "\n",
    "                # build the masks\n",
    "                # print(self._clustering)\n",
    "                m10 = m00.copy()  # we separate the copy from the add so as to not get converted to a matrix\n",
    "                m10[:] += self._mask_matrix[lind, :]\n",
    "\n",
    "                # print(self._mask_matrix.toarray())\n",
    "                # print(\"the m00\", m00)\n",
    "                # print(\"the left\", lind)\n",
    "                # print(\"what we add\", self._mask_matrix[lind, :].toarray())\n",
    "                # print(\"mask m10\", m10)\n",
    "                m01 = m00.copy()\n",
    "                m01[:] += self._mask_matrix[rind, :]\n",
    "                # print(\"the right\", rind)\n",
    "                # print(\"what we add\", self._mask_matrix[rind, :].toarray())\n",
    "                # print(\"mask m01\", m01)\n",
    "\n",
    "                # add the batch\n",
    "                batch_args.append((m00, m10, m01, f00, f11, ind, lind, rind, weight))\n",
    "                batch_masks.append(m10)\n",
    "                batch_masks.append(m01)\n",
    "\n",
    "            batch_masks = np.array(batch_masks)\n",
    "\n",
    "            # run the batch calculate the\n",
    "            if len(batch_args) > 0:\n",
    "                #print(\"the masks\", batch_masks)\n",
    "                fout = fm(\n",
    "                    batch_masks\n",
    "                )  ######################## call the model using the masks  #############################\n",
    "                if output_indexes is not None:  # making sure the indexing is correct\n",
    "                    fout = fout[:, output_indexes]\n",
    "                #print(\"output of the model\", fout)\n",
    "\n",
    "                eval_count += len(batch_masks)  # update evaluation count\n",
    "                # update the progress bar\n",
    "\n",
    "                if pbar is None and time.time() - start_time > 5:\n",
    "                    pbar = tqdm(total=total_evals, disable=silent, leave=False)\n",
    "                    pbar.update(eval_count)\n",
    "                if pbar is not None:\n",
    "                    pbar.update(len(batch_masks))\n",
    "\n",
    "            # use the results of the batch to add new nodes\n",
    "            # THIS IS HOW THE CODE TRAVERSES THE TREE CREATING ALL POSSIBLE MASKS\n",
    "            # print(batch_args)\n",
    "            for i in range(len(batch_args)):\n",
    "                m00, m10, m01, f00, f11, ind, lind, rind, weight = batch_args[i]\n",
    "\n",
    "                # get the evaluated model output on the two new masked inputs\n",
    "                f10 = fout[2 * i]\n",
    "                f01 = fout[2 * i + 1]\n",
    "\n",
    "                new_weight = weight\n",
    "                if fixed_context is None:\n",
    "                    new_weight /= 2  #\n",
    "                #print(\"new weight\", new_weight)\n",
    "                # elif fixed_context == 0:\n",
    "                #     self.dvalues[ind] += (f11 - f10 - f01 + f00) * weight # leave the interaction effect on the internal node\n",
    "                # elif fixed_context == 1:\n",
    "                #     self.dvalues[ind] -= (f11 - f10 - f01 + f00) * weight # leave the interaction effect on the internal node\n",
    "\n",
    "                ## The idea is to proceed\n",
    "\n",
    "                if fixed_context is None or fixed_context == 0:\n",
    "                    # recurse on the left node with zero context\n",
    "                    args = (m00, f00, f10, lind, new_weight)\n",
    "                    #print(-np.max(np.abs(f10 - f00)) * new_weight)\n",
    "                    q.put(\n",
    "                        (\n",
    "                            -np.max(np.abs(f10 - f00)) * new_weight,\n",
    "                            np.random.randn(),\n",
    "                            args,\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                    # recurse on the right node with zero context\n",
    "                    args = (m00, f00, f01, rind, new_weight)\n",
    "                    #print(-np.max(np.abs(f01 - f00)) * new_weight)\n",
    "                    q.put(\n",
    "                        (\n",
    "                            -np.max(np.abs(f01 - f00)) * new_weight,\n",
    "                            np.random.randn(),\n",
    "                            args,\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                if fixed_context is None or fixed_context == 1:\n",
    "                    # recurse on the left node with one context\n",
    "                    args = (m01, f01, f11, lind, new_weight)\n",
    "                    #print(-np.max(np.abs(f11 - f01)) * new_weight)\n",
    "                    q.put(\n",
    "                        (\n",
    "                            -np.max(np.abs(f11 - f01)) * new_weight,\n",
    "                            np.random.randn(),\n",
    "                            args,\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                    # recurse on the right node with one context\n",
    "                    args = (m10, f10, f11, rind, new_weight)\n",
    "                    #print(-np.max(np.abs(f11 - f10)) * new_weight)\n",
    "                    q.put(\n",
    "                        (\n",
    "                            -np.max(np.abs(f11 - f10)) * new_weight,\n",
    "                            np.random.randn(),\n",
    "                            args,\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "        if pbar is not None:\n",
    "            pbar.close()\n",
    "\n",
    "        self.last_eval_count = eval_count\n",
    "\n",
    "        return output_indexes, base_value\n",
    "\n",
    "    ###########################  NOT USED NOW #########################\n",
    "\n",
    "\n",
    "# def output_indexes_len(output_indexes):\n",
    "#     if output_indexes.startswith(\"max(\"):\n",
    "#         return int(output_indexes[4:-1])\n",
    "#     elif output_indexes.startswith(\"min(\"):\n",
    "#         return int(output_indexes[4:-1])\n",
    "#     elif output_indexes.startswith(\"max(abs(\"):\n",
    "#         return int(output_indexes[8:-2])\n",
    "#     elif not isinstance(output_indexes, str):\n",
    "#         return len(output_indexes)\n",
    "\n",
    "\n",
    "@njit\n",
    "def lower_credit(i, value, M, values, clustering):\n",
    "    if i < M:  # M number of features, i\n",
    "        values[i] += value\n",
    "        return\n",
    "    li = int(clustering[i - M, 0])  # get the left index of the top node\n",
    "    ri = int(clustering[i - M, 1])  # get the right index of the top node\n",
    "    group_size = int(clustering[i - M, 3])  # get the number of features in the top node\n",
    "    lsize = int(clustering[li - M, 3]) if li >= M else 1  #\n",
    "    rsize = int(clustering[ri - M, 3]) if ri >= M else 1\n",
    "    assert lsize + rsize == group_size\n",
    "    values[i] += value\n",
    "    lower_credit(li, values[i] * lsize / group_size, M, values, clustering)\n",
    "    lower_credit(ri, values[i] * rsize / group_size, M, values, clustering)\n",
    "\n",
    "# gonna keep the n-ary tree in it's own class for easier referencing\n",
    "class Node:\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        self.child = []\n",
    "        self.permutations = [] # this may not be the greatest idea??\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"({self.key}): {self.child} -> {self.permutations}\"\n",
    "\n",
    "# This function is to encode the dictionary to our specific structure\n",
    "def build_tree(d, root):\n",
    "    if isinstance(d, dict):\n",
    "        for key, value in d.items():\n",
    "            node = Node(key)\n",
    "            root.child.append(node)\n",
    "            build_tree(value, node)\n",
    "    elif isinstance(d, list):\n",
    "        for item in d:\n",
    "            node = Node(item)\n",
    "            root.child.append(node)\n",
    "    # get all the sibling permutations\n",
    "    generate_permutations(root)\n",
    "\n",
    "#generate all permutations of sibling nodes and assign it to the nodes\n",
    "def generate_permutations(node):\n",
    "    if not node.child:  # Leaf node\n",
    "        node.permutations = []\n",
    "        return\n",
    "\n",
    "    children_keys = [child.key for child in node.child]\n",
    "    node.permutations = {}\n",
    "\n",
    "    for i, child in enumerate(node.child):\n",
    "        excluded = children_keys[:i] + children_keys[i + 1:]\n",
    "        generate_permutations(child)\n",
    "\n",
    "        # Generate all unique combinations of permutations for each child\n",
    "        child.permutations = list(all_subsets(excluded))\n",
    "\n",
    "def all_subsets(iterable):\n",
    "    \"Return all subsets of a given iterable.\"\n",
    "    return chain.from_iterable(combinations(iterable, n) for n in range(len(iterable) + 1))\n",
    "\n",
    "\n",
    "# Functions to generate the base masks for every node in the hierarchy\n",
    "def get_all_leaf_values(node):\n",
    "    leaves = []\n",
    "    if not node.child:\n",
    "        leaves.append(node.key)\n",
    "    else:\n",
    "        for child in node.child:\n",
    "            leaves.extend(get_all_leaf_values(child))\n",
    "    return leaves\n",
    "\n",
    "def create_masks1(node, columns):\n",
    "    masks = [np.zeros(len(columns),dtype=bool)] # not very efficient for huge trees? maybe??\n",
    "    keys = [()]\n",
    "\n",
    "    if not node.child:  # Check if the child list is empty\n",
    "        mask = columns == node.key\n",
    "        masks.append(mask)\n",
    "        keys.append(node.key)\n",
    "    else:\n",
    "        # Create mask for current node\n",
    "        current_node_mask = columns.isin(get_all_leaf_values(node))\n",
    "        masks.append(current_node_mask)\n",
    "        keys.append(node.key)\n",
    "\n",
    "        # Recursively create masks for all child nodes\n",
    "        for subset in node.child:\n",
    "            child_masks, child_keys = create_masks1(subset, columns)\n",
    "            masks.extend(child_masks)\n",
    "            keys.extend(child_keys)\n",
    "\n",
    "    return  masks, keys\n",
    "\n",
    "\n",
    "# combine all the permutations along depth first traversal\n",
    "def generate_paths_and_combinations(node):\n",
    "    paths = []\n",
    "\n",
    "    def dfs(current_node, current_path):\n",
    "        current_path.append((current_node.key, current_node.permutations))\n",
    "\n",
    "        if not current_node.child:  # Leaf node\n",
    "            paths.append(current_path[:])  # Make a copy of current_path\n",
    "        else:\n",
    "            for child in current_node.child:\n",
    "                dfs(child, current_path)\n",
    "\n",
    "        current_path.pop()  # Backtrack\n",
    "\n",
    "    dfs(node, [])\n",
    "\n",
    "    combinations_list = []\n",
    "\n",
    "    for path in paths:\n",
    "        filtered_path = [(key, perms) for key, perms in path if perms]\n",
    "        if filtered_path:\n",
    "            node_keys, permutations = zip(*filtered_path)\n",
    "            path_combinations = list(product(*permutations))\n",
    "            last_key = node_keys[-1]\n",
    "            for combination in path_combinations:\n",
    "                combinations_list.append((last_key, combination))\n",
    "\n",
    "    return combinations_list\n",
    "\n",
    "# functions to combine the masks for all the permutations created\n",
    "def combine_masks(masks):\n",
    "    combined_mask = np.logical_or.reduce(masks)\n",
    "    return combined_mask\n",
    "\n",
    "\n",
    "# def create_combined_masks(combinations, masks_dict):\n",
    "#     combined_masks = []\n",
    "#     for last_key, combination in combinations:\n",
    "#         masks = [masks_dict[key] for keys in combination for key in keys]\n",
    "#         if masks:\n",
    "#             combined_mask = combine_masks(masks)\n",
    "#             combined_masks.append((last_key, combined_mask))\n",
    "\n",
    "#             # Add the combined mask with the last key's mask\n",
    "#             if last_key in masks_dict:\n",
    "#                 combined_mask_with_last_key = combine_masks(masks + [masks_dict[last_key]])\n",
    "#                 combined_masks.append((last_key, combined_mask_with_last_key))\n",
    "#     return combined_masks\n",
    "\n",
    "\n",
    "def create_combined_masks(combinations, masks_dict):\n",
    "    combined_masks = []\n",
    "    for last_key, combination in combinations:\n",
    "        # Collect masks for each key in the combination\n",
    "        masks = []\n",
    "        for keys in combination:\n",
    "            if isinstance(keys, tuple) and not keys:\n",
    "                # Handle empty tuple (())\n",
    "                continue\n",
    "            for key in keys:\n",
    "                if key in masks_dict:\n",
    "                    masks.append(masks_dict[key])\n",
    "\n",
    "        if masks:\n",
    "            # Combine all the masks using logical OR\n",
    "            combined_mask = combine_masks(masks)\n",
    "            combined_masks.append((last_key, combined_mask))\n",
    "\n",
    "            # Add the combined mask with the last key's mask if it's present\n",
    "            if last_key in masks_dict:\n",
    "                combined_mask_with_last_key = combine_masks(masks + [masks_dict[last_key]])\n",
    "                combined_masks.append((last_key, combined_mask_with_last_key))\n",
    "        else:\n",
    "            # If no masks were found, create a mask of all False values\n",
    "            combined_mask = np.zeros_like(list(masks_dict.values())[0])\n",
    "            combined_masks.append((last_key, combined_mask))\n",
    "\n",
    "            if last_key in masks_dict:\n",
    "                combined_mask_with_last_key = combine_masks([combined_mask, masks_dict[last_key]])\n",
    "                combined_masks.append((last_key, combined_mask_with_last_key))\n",
    "    return combined_masks\n",
    "\n",
    "# this may not be needed as we know that all the first values are off and all second values are off\n",
    "def map_combinations_to_unique_masks(combined_masks, unique_masks):\n",
    "    # Create a mapping from mask arrays to their unique index\n",
    "    unique_mask_index_map = {tuple(mask): idx for idx, mask in enumerate(unique_masks)}\n",
    "\n",
    "    # Create dictionaries to hold the mapping of last_key to unique mask indexes for ON and OFF\n",
    "    last_key_to_off_indexes = {}\n",
    "    last_key_to_on_indexes = {}\n",
    "\n",
    "    for i, (last_key, combined_mask) in enumerate(combined_masks):\n",
    "        mask_tuple = tuple(combined_mask)\n",
    "        unique_index = unique_mask_index_map[mask_tuple]\n",
    "\n",
    "        if i % 2 == 0:  # Even index -> OFF value\n",
    "            if last_key not in last_key_to_off_indexes:\n",
    "                last_key_to_off_indexes[last_key] = []\n",
    "            last_key_to_off_indexes[last_key].append(unique_index)\n",
    "        else:  # Odd index -> ON value\n",
    "            if last_key not in last_key_to_on_indexes:\n",
    "                last_key_to_on_indexes[last_key] = []\n",
    "            last_key_to_on_indexes[last_key].append(unique_index)\n",
    "\n",
    "    return last_key_to_off_indexes, last_key_to_on_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "b051e4d7-258e-4fce-a802-c8bf8acf61ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a masker from partition tree\n",
    "masker = shap.maskers.Partition(X, clustering=partition_clustering)\n",
    "\n",
    "# build explainer objects\n",
    "# raw_explainer = PartitionExplainer2(model.predict, X)\n",
    "masker_explainer = PartitionExplainer2(model.predict, masker)\n",
    "\n",
    "# compute SHAP values\n",
    "# raw_shap_values = raw_explainer(instance)\n",
    "masker_shap_values = masker_explainer(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "90964449-8d74-4376-9371-6339e201699c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ".values =\n",
       "array([[ 1.48833262,  0.06782281,  0.60202918,  0.00896832, -0.08800008,\n",
       "         0.09939416, -0.62810122,  0.91961976]])\n",
       "\n",
       ".base_values =\n",
       "array([1.96104483])\n",
       "\n",
       ".data =\n",
       "array([[   8.3252    ,   41.        ,    6.98412698,    1.02380952,\n",
       "         322.        ,    2.55555556,   37.88      , -122.23      ]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masker_shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2ebadc52-a3e3-4e7f-80b0-768b2e5aac7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True False False  True False]\n",
      "model results [3.33367664]\n",
      "[ True  True False False  True  True  True  True]\n",
      "model results [3.64675765]\n",
      "[False False  True False False False False False]\n",
      "model results [2.40634892]\n",
      "[ True  True  True  True False  True  True False]\n",
      "model results [3.42766333]\n",
      "[ True False  True  True  True  True  True  True]\n",
      "model results [4.2179181]\n",
      "[False  True  True  True False False  True  True]\n",
      "model results [2.47420211]\n",
      "[False  True  True  True False  True  True False]\n",
      "model results [1.77351641]\n",
      "[False  True  True False False False False False]\n",
      "model results [2.38869872]\n",
      "[ True  True  True False  True  True False  True]\n",
      "model results [5.07639598]\n",
      "[ True False False  True  True  True False  True]\n",
      "model results [4.23792113]\n",
      "[False False False False False False False False]\n",
      "model results [1.96104483]\n",
      "[False  True False False False False False False]\n",
      "model results [1.91302233]\n",
      "[ True  True  True  True  True False  True  True]\n",
      "model results [4.33936054]\n",
      "[False False False False False  True False False]\n",
      "model results [2.07515379]\n",
      "[ True False False False  True  True False  True]\n",
      "model results [4.21841456]\n",
      "[False False False False  True False False  True]\n",
      "model results [3.0550008]\n",
      "[ True  True  True  True  True  True  True  True]\n",
      "model results [4.43111038]\n",
      "[ True  True False  True  True  True False  True]\n",
      "model results [4.33266055]\n",
      "[False False False  True False False False False]\n",
      "model results [1.94916851]\n",
      "[ True False False False  True False False  True]\n",
      "model results [3.99541884]\n",
      "[False  True  True  True False False False False]\n",
      "model results [2.38980983]\n",
      "[ True False  True False  True  True False  True]\n",
      "model results [4.99553056]\n",
      "[False  True  True  True False False  True False]\n",
      "model results [1.84978719]\n",
      "[False  True False  True False False  True False]\n",
      "model results [1.41006832]\n",
      "[ True  True False False  True  True False  True]\n",
      "model results [4.33277667]\n",
      "[False  True  True  True  True False  True  True]\n",
      "model results [2.27931443]\n",
      "[ True False  True  True  True  True False  True]\n",
      "model results [5.03424974]\n",
      "[False  True  True  True  True  True  True  True]\n",
      "model results [2.26732835]\n",
      "[False False  True False False False  True False]\n",
      "model results [1.84746525]\n",
      "[False False  True  True False False  True False]\n",
      "model results [1.85802786]\n",
      "[ True False False False False  True False  True]\n",
      "model results [4.34381093]\n",
      "[False False False False  True False False False]\n",
      "model results [1.87909234]\n",
      "[ True  True  True  True  True  True  True False]\n",
      "model results [3.4799016]\n",
      "[ True False False False  True  True False False]\n",
      "model results [3.2661935]\n",
      "[False  True  True False False False  True False]\n",
      "model results [1.84057501]\n",
      "[ True  True  True False  True  True  True  True]\n",
      "model results [4.39845093]\n",
      "[ True False False  True  True  True  True  True]\n",
      "model results [3.4337267]\n",
      "[ True  True  True  True False  True  True  True]\n",
      "model results [4.27122111]\n",
      "[False  True False False False False  True False]\n",
      "model results [1.42177547]\n",
      "[ True  True  True  True  True  True False  True]\n",
      "model results [5.09025015]\n",
      "[ True False False False  True  True  True  True]\n",
      "model results [3.42129807]\n",
      "[ True False False False False False False False]\n",
      "model results [3.28551828]\n",
      "[False False False False  True  True False  True]\n",
      "model results [3.28222193]\n",
      "[False  True  True  True  True False  True False]\n",
      "model results [1.56388644]\n",
      "[False False False False False False  True False]\n",
      "model results [1.47446106]\n",
      "[ True False False False False  True False False]\n",
      "model results [3.41886612]\n",
      "[False False False  True False False  True False]\n",
      "model results [1.46716395]\n",
      "[False False False False False False False  True]\n",
      "model results [3.13031911]\n",
      "[False False  True  True False False False False]\n",
      "model results [2.40637742]\n",
      "[False  True False  True False False False False]\n",
      "model results [1.90364804]\n",
      "[ True False  True False  True  True  True  True]\n",
      "model results [4.18505755]\n",
      "[ True  True False  True  True  True  True  True]\n",
      "model results [3.65967889]\n",
      "{'MedInc': 0, 'HouseAge': 1, 'AveRooms': 2, 'AveBedrms': 3, 'Population': 4, 'AveOccup': 5, 'Latitude': 6, 'Longitude': 7}\n",
      "off 10 [1.96104483] on 13 [2.07515379] 8\n",
      "the values [0.01426362]\n",
      "the marginal [0.01426362]\n",
      "off 41 [3.28551828] on 45 [3.41886612] 8\n",
      "the values [0.01666848]\n",
      "the marginal [0.01666848]\n",
      "off 15 [3.0550008] on 42 [3.28222193] 8\n",
      "the values [0.02840264]\n",
      "the marginal [0.02840264]\n",
      "off 19 [3.99541884] on 14 [4.21841456] 8\n",
      "the values [0.02787446]\n",
      "the marginal [0.02787446]\n",
      "off 22 [1.84978719] on 6 [1.77351641] 8\n",
      "the values [-0.00953385]\n",
      "the marginal [-0.00953385]\n",
      "off 0 [3.33367664] on 3 [3.42766333] 8\n",
      "the values [0.01174834]\n",
      "the marginal [0.01174834]\n",
      "off 25 [2.27931443] on 27 [2.26732835] 8\n",
      "the values [-0.00149826]\n",
      "the marginal [-0.00149826]\n",
      "off 12 [4.33936054] on 16 [4.43111038] 8\n",
      "the values [0.01146873]\n",
      "the marginal [0.01146873]\n",
      "off 10 [1.96104483] on 41 [3.28551828] 8\n",
      "the values [0.16555918]\n",
      "the marginal [0.16555918]\n",
      "off 13 [2.07515379] on 45 [3.41886612] 8\n",
      "the values [0.16796404]\n",
      "the marginal [0.16796404]\n",
      "off 15 [3.0550008] on 19 [3.99541884] 8\n",
      "the values [0.11755225]\n",
      "the marginal [0.11755225]\n",
      "off 42 [3.28222193] on 14 [4.21841456] 8\n",
      "the values [0.11702408]\n",
      "the marginal [0.11702408]\n",
      "off 22 [1.84978719] on 0 [3.33367664] 8\n",
      "the values [0.18548618]\n",
      "the marginal [0.18548618]\n",
      "off 6 [1.77351641] on 3 [3.42766333] 8\n",
      "the values [0.20676836]\n",
      "the marginal [0.20676836]\n",
      "off 25 [2.27931443] on 12 [4.33936054] 8\n",
      "the values [0.25750576]\n",
      "the marginal [0.25750576]\n",
      "off 27 [2.26732835] on 16 [4.43111038] 8\n",
      "the values [0.27047275]\n",
      "the marginal [0.27047275]\n",
      "off 10 [1.96104483] on 47 [3.13031911] 8\n",
      "the values [0.14615928]\n",
      "the marginal [0.14615928]\n",
      "off 31 [1.87909234] on 15 [3.0550008] 8\n",
      "the values [0.14698856]\n",
      "the marginal [0.14698856]\n",
      "off 45 [3.41886612] on 30 [4.34381093] 8\n",
      "the values [0.1156181]\n",
      "the marginal [0.1156181]\n",
      "off 33 [3.2661935] on 14 [4.21841456] 8\n",
      "the values [0.11902763]\n",
      "the marginal [0.11902763]\n",
      "off 22 [1.84978719] on 5 [2.47420211] 8\n",
      "the values [0.07805187]\n",
      "the marginal [0.07805187]\n",
      "off 43 [1.56388644] on 25 [2.27931443] 8\n",
      "the values [0.0894285]\n",
      "the marginal [0.0894285]\n",
      "off 3 [3.42766333] on 37 [4.27122111] 8\n",
      "the values [0.10544472]\n",
      "the marginal [0.10544472]\n",
      "off 32 [3.4799016] on 16 [4.43111038] 8\n",
      "the values [0.1189011]\n",
      "the marginal [0.1189011]\n",
      "off 10 [1.96104483] on 31 [1.87909234] 8\n",
      "the values [-0.01024406]\n",
      "the marginal [-0.01024406]\n",
      "off 47 [3.13031911] on 15 [3.0550008] 8\n",
      "the values [-0.00941479]\n",
      "the marginal [-0.00941479]\n",
      "off 45 [3.41886612] on 33 [3.2661935] 8\n",
      "the values [-0.01908408]\n",
      "the marginal [-0.01908408]\n",
      "off 30 [4.34381093] on 14 [4.21841456] 8\n",
      "the values [-0.01567455]\n",
      "the marginal [-0.01567455]\n",
      "off 22 [1.84978719] on 43 [1.56388644] 8\n",
      "the values [-0.03573759]\n",
      "the marginal [-0.03573759]\n",
      "off 5 [2.47420211] on 25 [2.27931443] 8\n",
      "the values [-0.02436096]\n",
      "the marginal [-0.02436096]\n",
      "off 3 [3.42766333] on 32 [3.4799016] 8\n",
      "the values [0.00652978]\n",
      "the marginal [0.00652978]\n",
      "off 37 [4.27122111] on 16 [4.43111038] 8\n",
      "the values [0.01998616]\n",
      "the marginal [0.01998616]\n",
      "off 10 [1.96104483] on 11 [1.91302233] 4\n",
      "the values [-0.01200562]\n",
      "the marginal [-0.01200562]\n",
      "off 29 [1.85802786] on 22 [1.84978719] 4\n",
      "the values [-0.00206017]\n",
      "the marginal [-0.00206017]\n",
      "off 14 [4.21841456] on 24 [4.33277667] 4\n",
      "the values [0.02859053]\n",
      "the marginal [0.02859053]\n",
      "off 4 [4.2179181] on 16 [4.43111038] 4\n",
      "the values [0.05329807]\n",
      "the marginal [0.05329807]\n",
      "off 10 [1.96104483] on 44 [1.47446106] 8\n",
      "the values [-0.06082297]\n",
      "the marginal [-0.06082297]\n",
      "off 48 [2.40637742] on 29 [1.85802786] 8\n",
      "the values [-0.0685437]\n",
      "the marginal [-0.0685437]\n",
      "off 11 [1.91302233] on 38 [1.42177547] 8\n",
      "the values [-0.06140586]\n",
      "the marginal [-0.06140586]\n",
      "off 20 [2.38980983] on 22 [1.84978719] 8\n",
      "the values [-0.06750283]\n",
      "the marginal [-0.06750283]\n",
      "off 14 [4.21841456] on 40 [3.42129807] 8\n",
      "the values [-0.09963956]\n",
      "the marginal [-0.09963956]\n",
      "off 26 [5.03424974] on 4 [4.2179181] 8\n",
      "the values [-0.10204146]\n",
      "the marginal [-0.10204146]\n",
      "off 24 [4.33277667] on 1 [3.64675765] 8\n",
      "the values [-0.08575238]\n",
      "the marginal [-0.08575238]\n",
      "off 39 [5.09025015] on 16 [4.43111038] 8\n",
      "the values [-0.08239247]\n",
      "the marginal [-0.08239247]\n",
      "off 10 [1.96104483] on 18 [1.94916851] 16\n",
      "the values [-0.00074227]\n",
      "the marginal [-0.00074227]\n",
      "off 2 [2.40634892] on 48 [2.40637742] 16\n",
      "the values [1.78134069e-06]\n",
      "the marginal [1.78134069e-06]\n",
      "off 44 [1.47446106] on 46 [1.46716395] 16\n",
      "the values [-0.00045607]\n",
      "the marginal [-0.00045607]\n",
      "off 28 [1.84746525] on 29 [1.85802786] 16\n",
      "the values [0.00066016]\n",
      "the marginal [0.00066016]\n",
      "off 11 [1.91302233] on 49 [1.90364804] 16\n",
      "the values [-0.00058589]\n",
      "the marginal [-0.00058589]\n",
      "off 7 [2.38869872] on 20 [2.38980983] 16\n",
      "the values [6.94442913e-05]\n",
      "the marginal [6.94442913e-05]\n",
      "off 38 [1.42177547] on 23 [1.41006832] 16\n",
      "the values [-0.0007317]\n",
      "the marginal [-0.0007317]\n",
      "off 34 [1.84057501] on 22 [1.84978719] 16\n",
      "the values [0.00057576]\n",
      "the marginal [0.00057576]\n",
      "off 14 [4.21841456] on 9 [4.23792113] 16\n",
      "the values [0.00121916]\n",
      "the marginal [0.00121916]\n",
      "off 21 [4.99553056] on 26 [5.03424974] 16\n",
      "the values [0.00241995]\n",
      "the marginal [0.00241995]\n",
      "off 40 [3.42129807] on 36 [3.4337267] 16\n",
      "the values [0.00077679]\n",
      "the marginal [0.00077679]\n",
      "off 50 [4.18505755] on 4 [4.2179181] 16\n",
      "the values [0.00205378]\n",
      "the marginal [0.00205378]\n",
      "off 24 [4.33277667] on 17 [4.33266055] 16\n",
      "the values [-7.25775957e-06]\n",
      "the marginal [-7.25775957e-06]\n",
      "off 8 [5.07639598] on 39 [5.09025015] 16\n",
      "the values [0.00086589]\n",
      "the marginal [0.00086589]\n",
      "off 1 [3.64675765] on 51 [3.65967889] 16\n",
      "the values [0.00080758]\n",
      "the marginal [0.00080758]\n",
      "off 35 [4.39845093] on 16 [4.43111038] 16\n",
      "the values [0.00204122]\n",
      "the marginal [0.00204122]\n",
      "off 10 [1.96104483] on 2 [2.40634892] 16\n",
      "the values [0.02783151]\n",
      "the marginal [0.02783151]\n",
      "off 18 [1.94916851] on 48 [2.40637742] 16\n",
      "the values [0.02857556]\n",
      "the marginal [0.02857556]\n",
      "off 44 [1.47446106] on 28 [1.84746525] 16\n",
      "the values [0.02331276]\n",
      "the marginal [0.02331276]\n",
      "off 46 [1.46716395] on 29 [1.85802786] 16\n",
      "the values [0.02442899]\n",
      "the marginal [0.02442899]\n",
      "off 11 [1.91302233] on 7 [2.38869872] 16\n",
      "the values [0.02972977]\n",
      "the marginal [0.02972977]\n",
      "off 49 [1.90364804] on 20 [2.38980983] 16\n",
      "the values [0.03038511]\n",
      "the marginal [0.03038511]\n",
      "off 38 [1.42177547] on 34 [1.84057501] 16\n",
      "the values [0.02617497]\n",
      "the marginal [0.02617497]\n",
      "off 23 [1.41006832] on 22 [1.84978719] 16\n",
      "the values [0.02748243]\n",
      "the marginal [0.02748243]\n",
      "off 14 [4.21841456] on 21 [4.99553056] 16\n",
      "the values [0.04856975]\n",
      "the marginal [0.04856975]\n",
      "off 9 [4.23792113] on 26 [5.03424974] 16\n",
      "the values [0.04977054]\n",
      "the marginal [0.04977054]\n",
      "off 40 [3.42129807] on 50 [4.18505755] 16\n",
      "the values [0.04773497]\n",
      "the marginal [0.04773497]\n",
      "off 36 [3.4337267] on 4 [4.2179181] 16\n",
      "the values [0.04901196]\n",
      "the marginal [0.04901196]\n",
      "off 24 [4.33277667] on 8 [5.07639598] 16\n",
      "the values [0.04647621]\n",
      "the marginal [0.04647621]\n",
      "off 17 [4.33266055] on 39 [5.09025015] 16\n",
      "the values [0.04734935]\n",
      "the marginal [0.04734935]\n",
      "off 1 [3.64675765] on 35 [4.39845093] 16\n",
      "the values [0.04698083]\n",
      "the marginal [0.04698083]\n",
      "off 51 [3.65967889] on 16 [4.43111038] 16\n",
      "the values [0.04821447]\n",
      "the marginal [0.04821447]\n",
      "SHAP Values: .values =\n",
      "array([[[ 1.48833262],\n",
      "        [ 0.06782281],\n",
      "        [ 0.60202918],\n",
      "        [ 0.00896832],\n",
      "        [-0.08800008],\n",
      "        [ 0.09939416],\n",
      "        [-0.62810122],\n",
      "        [ 0.91961976]]])\n",
      "\n",
      ".base_values =\n",
      "array([1.96104483])\n",
      "\n",
      ".data =\n",
      "array([[   8.3252    ,   41.        ,    6.98412698,    1.02380952,\n",
      "         322.        ,    2.55555556,   37.88      , -122.23      ]])\n"
     ]
    }
   ],
   "source": [
    "masker = shap.maskers.Independent(X)  # Use Independent masker if clustering is not desired\n",
    "\n",
    "# Build the explainer with the partition hierarchy\n",
    "partition_explainer = PartitionExplainer2(model.predict, masker, partition_tree=partition_hierarchy)\n",
    "\n",
    "# Compute SHAP values for a given instance\n",
    "#instance = X[0]  # Replace with the instance you want to explain\n",
    "shap_values = partition_explainer(instance)\n",
    "\n",
    "# Print the SHAP values\n",
    "print(\"SHAP Values:\", shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a301249-17ed-43f1-9430-fb7b7d6496ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "array([[ 1.48833262,  0.06782281,  0.60202918,  0.00896832, -0.08800008,\n",
    "         0.09939416, -0.62810122,  0.91961976]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31552692-93e4-41fd-a1a7-645173a5647e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def9e6be-177f-40d0-ab0b-07c815229f62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827a45cf-a513-4b61-9597-90136b87a9c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef7d88c-5cbb-402d-bfb0-fd5dbdc30ff3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "winter_vals",
   "language": "python",
   "name": "winter_vals"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
