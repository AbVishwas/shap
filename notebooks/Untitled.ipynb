{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ced130b-dbac-4c6c-a0bf-0762b6071995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue #multi-producer, multi-consumer queues\n",
    "import time # time execution\n",
    "\n",
    "import numpy as np # numpy base\n",
    "from numba import njit # just in time compiler\n",
    "from tqdm.auto import tqdm # progress bar\n",
    "\n",
    "from shap import Explanation, links # shap modules\n",
    "from shap.models import Model\n",
    "from shap.utils import MaskedModel, OpChain, make_masks, safe_isinstance\n",
    "from shap.explainers._explainer import Explainer\n",
    "\n",
    "\n",
    "class PartitionExplainer2(Explainer):\n",
    "    \"\"\"Uses the Partition SHAP method to explain the output of any function.\n",
    "\n",
    "    Partition SHAP computes Shapley values recursively through a hierarchy of features, this\n",
    "    hierarchy defines feature coalitions and results in the Owen  values from game theory.\n",
    "\n",
    "    The PartitionExplainer has two particularly nice properties:\n",
    "\n",
    "    1) PartitionExplainer is model-agnostic but when using a balanced partition tree only has\n",
    "       quadratic exact runtime (in term of the number of input features). This is in contrast to the\n",
    "       exponential exact runtime of KernelExplainer or SamplingExplainer.\n",
    "    2) PartitionExplainer always assigns to groups of correlated features the credit that set of features\n",
    "       would have had if treated as a group. This means if the hierarchical clustering given to\n",
    "       PartitionExplainer groups correlated features together, then feature correlations are\n",
    "       \"accounted for\" in the sense that the total credit assigned to a group of tightly dependent features\n",
    "       does not depend on how they behave if their correlation structure was broken during the explanation's\n",
    "       perturbation process.\n",
    "    Note that for linear models the Owen values that PartitionExplainer returns are the same as the standard\n",
    "    non-hierarchical Shapley values.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, masker, partition_tree = None, *, output_names=None, link=links.identity, linearize_link=True,\n",
    "                 feature_names=None, **call_args):\n",
    "        \"\"\"Build a PartitionExplainer for the given model with the given masker.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        model : function\n",
    "            User supplied function that takes a matrix of samples (# samples x # features) and\n",
    "            computes the output of the model for those samples.\n",
    "\n",
    "        masker : function or numpy.array or pandas.DataFrame or tokenizer\n",
    "            The function used to \"mask\" out hidden features of the form `masker(mask, x)`. It takes a\n",
    "            single input sample and a binary mask and returns a matrix of masked samples. These\n",
    "            masked samples will then be evaluated using the model function and the outputs averaged.\n",
    "            As a shortcut for the standard masking using by SHAP you can pass a background data matrix\n",
    "            instead of a function and that matrix will be used for masking. Domain specific masking\n",
    "            functions are available in shap such as shap.maksers.Image for images and shap.maskers.Text\n",
    "            for text.\n",
    "\n",
    "        partition_tree : None or function or numpy.array ################################ NOT CURRENTLY IMPLEMENTED #####################################\n",
    "            A hierarchical clustering of the input features represented by a matrix that follows the format\n",
    "            used by scipy.cluster.hierarchy (see the notebooks_html/partition_explainer directory an example).\n",
    "            If this is a function then the function produces a clustering matrix when given a single input\n",
    "            example. If you are using a standard SHAP masker object then you can pass masker.clustering\n",
    "            to use that masker's built-in clustering of the features, or if partition_tree is None then\n",
    "            masker.clustering will be used by default.\n",
    "\n",
    "        Examples\n",
    "        --------\n",
    "        See `Partition explainer examples <https://shap.readthedocs.io/en/latest/api_examples/explainers/PartitionExplainer.html>`_\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__(model, masker,partition_tree = None, link=link, linearize_link=linearize_link, algorithm=\"partition\", \\\n",
    "                         output_names = output_names, feature_names=feature_names)\n",
    "\n",
    "        # convert dataframes\n",
    "        # if isinstance(masker, pd.DataFrame):\n",
    "        #     masker = TabularMasker(masker)\n",
    "        # elif isinstance(masker, np.ndarray) and len(masker.shape) == 2:\n",
    "        #     masker = TabularMasker(masker)\n",
    "        # elif safe_isinstance(masker, \"transformers.PreTrainedTokenizer\"):\n",
    "        #     masker = TextMasker(masker)\n",
    "        # self.masker = masker\n",
    "\n",
    "        # TODO: maybe? if we have a tabular masker then we build a PermutationExplainer that we\n",
    "        # will use for sampling\n",
    "        self.input_shape = masker.shape[1:] if hasattr(masker, \"shape\") and not callable(masker.shape) else None\n",
    "        # self.output_names = output_names\n",
    "        if not safe_isinstance(self.model, \"shap.models.Model\"):\n",
    "            self.model = Model(self.model)#lambda *args: np.array(model(*args))\n",
    "        self.expected_value = None\n",
    "        self._curr_base_value = None\n",
    "        if getattr(self.masker, \"clustering\", None) is None:\n",
    "            raise ValueError(\"The passed masker must have a .clustering attribute defined! Try shap.maskers.Partition(data) for example.\")\n",
    "\n",
    "        ###########################\n",
    "        # the rest of the partition tree use is not done\n",
    "        ###########################\n",
    "\n",
    "        if partition_tree is None:\n",
    "            if not hasattr(masker, \"partition_tree\"):\n",
    "                raise ValueError(\"The passed masker does not have masker.clustering, so the partition_tree must be passed!\")\n",
    "            self.partition_tree = masker.clustering\n",
    "        else:\n",
    "            if partition_tree \n",
    "            \"\"\"\n",
    "            check partition tree here \n",
    "            \n",
    "            \"\"\"\n",
    "            self.partition_tree = partition_tree\n",
    "            \n",
    "            \n",
    "\n",
    "        # handle higher dimensional tensor inputs\n",
    "        if self.input_shape is not None and len(self.input_shape) > 1:\n",
    "            self._reshaped_model = lambda x: self.model(x.reshape(x.shape[0], *self.input_shape))\n",
    "        else:\n",
    "            self._reshaped_model = self.model\n",
    "\n",
    "        # if we don't have a dynamic clustering algorithm then can precowe mpute\n",
    "        # a lot of information\n",
    "        if not callable(self.masker.clustering):\n",
    "            self._clustering = self.masker.clustering #\n",
    "            self._mask_matrix = make_masks(self._clustering) # make masks argument\n",
    "\n",
    "        # if we have gotten default arguments for the call function we need to wrap ourselves in a new class that\n",
    "        # has a call function with those new default arguments\n",
    "        if len(call_args) > 0:\n",
    "            class PartitionExplainer(self.__class__):\n",
    "                # this signature should match the __call__ signature of the class defined below\n",
    "                def __call__(self, *args, max_evals=500, fixed_context=None, main_effects=False, error_bounds=False, batch_size=\"auto\",\n",
    "                             outputs=None, silent=False):\n",
    "                    return super().__call__(\n",
    "                        *args, max_evals=max_evals, fixed_context=fixed_context, main_effects=main_effects, error_bounds=error_bounds,\n",
    "                        batch_size=batch_size, outputs=outputs, silent=silent\n",
    "                    )\n",
    "            PartitionExplainer.__call__.__doc__ = self.__class__.__call__.__doc__\n",
    "            self.__class__ = PartitionExplainer\n",
    "            for k, v in call_args.items():\n",
    "                self.__call__.__kwdefaults__[k] = v\n",
    "\n",
    "    # note that changes to this function signature should be copied to the default call argument wrapper above\n",
    "    def __call__(self, *args, max_evals=500, fixed_context=None, main_effects=False, error_bounds=False, batch_size=\"auto\",\n",
    "                 outputs=None, silent=False):\n",
    "        \"\"\"Explain the output of the model on the given arguments.\"\"\"\n",
    "        return super().__call__(\n",
    "            *args, max_evals=max_evals, fixed_context=fixed_context, main_effects=main_effects, error_bounds=error_bounds, batch_size=batch_size,\n",
    "            outputs=outputs, silent=silent\n",
    "        )\n",
    "\n",
    "    def explain_row(self, *row_args, max_evals, main_effects, error_bounds, batch_size, outputs, silent, fixed_context = \"auto\"):\n",
    "        \"\"\"Explains a single row and returns the tuple (row_values, row_expected_values, row_mask_shapes).\"\"\"\n",
    "        if fixed_context == \"auto\":\n",
    "            # if isinstance(self.masker, maskers.Text):\n",
    "            #     fixed_context = 1 # we err on the side of speed for text models\n",
    "            # else:\n",
    "            fixed_context = None\n",
    "        elif fixed_context not in [0, 1, None]:\n",
    "            raise ValueError(\"Unknown fixed_context value passed (must be 0, 1 or None): %s\" %fixed_context) # fixes fixed context\n",
    "\n",
    "        # build a masked versio  of the model for the current input sample\n",
    "        fm = MaskedModel(self.model, self.masker, self.link, self.linearize_link, *row_args)\n",
    "\n",
    "        # make sure we have the base value and current value outputs\n",
    "        M = len(fm)\n",
    "        m00 = np.zeros(M, dtype=bool) # all false the size of the masked model\n",
    "        # if not fixed background or no base value assigned then compute base value for a row\n",
    "        if self._curr_base_value is None or not getattr(self.masker, \"fixed_background\", False):\n",
    "            self._curr_base_value = fm(m00.reshape(1, -1), zero_index=0)[0] # the zero index param tells the masked model what the baseline is\n",
    "        f11 = fm(~m00.reshape(1, -1))[0] #compute the complement value of the baseline, all ones\n",
    "\n",
    "        if callable(self.masker.clustering):\n",
    "            self._clustering = self.masker.clustering(*row_args) #\n",
    "            print(self._clustering)\n",
    "            self._mask_matrix = make_masks(self._clustering) #  mask matrix using the clustering information\n",
    "            #print(self._mask_matrix)\n",
    "\n",
    "        if hasattr(self._curr_base_value, 'shape') and len(self._curr_base_value.shape) > 0:\n",
    "            if outputs is None:\n",
    "                outputs = np.arange(len(self._curr_base_value))\n",
    "            elif isinstance(outputs, OpChain):\n",
    "                outputs = outputs.apply(Explanation(f11)).values\n",
    "\n",
    "            out_shape = (2*self._clustering.shape[0]+1, len(outputs))\n",
    "        else:\n",
    "            out_shape = (2*self._clustering.shape[0]+1,)\n",
    "\n",
    "        if max_evals == \"auto\":\n",
    "            max_evals = 500\n",
    "\n",
    "        self.values = np.zeros(out_shape)\n",
    "        self.dvalues = np.zeros(out_shape)\n",
    "\n",
    "        print(self._curr_base_value, f11)\n",
    "        print(outputs)\n",
    "\n",
    "\n",
    "\n",
    "        self.owen(fm, self._curr_base_value, f11, max_evals - 2, outputs, fixed_context, batch_size, silent) #call the function to get the values\n",
    "\n",
    "        # if False:\n",
    "        #     if self.multi_output:\n",
    "        #         return [self.dvalues[:,i] for i in range(self.dvalues.shape[1])], oinds\n",
    "        #     else:\n",
    "        #         return self.dvalues.copy(), oinds\n",
    "        # else:\n",
    "        # drop the interaction terms down onto self.values\n",
    "        self.values[:] = self.dvalues\n",
    "\n",
    "        lower_credit(len(self.dvalues) - 1, 0, M, self.values, self._clustering)\n",
    "\n",
    "        return {\n",
    "            \"values\": self.values[:M].copy(),\n",
    "            \"expected_values\": self._curr_base_value if outputs is None else self._curr_base_value[outputs],\n",
    "            \"mask_shapes\": [s + out_shape[1:] for s in fm.mask_shapes],\n",
    "            \"main_effects\": None,\n",
    "            \"hierarchical_values\": self.dvalues.copy(),\n",
    "            \"clustering\": self._clustering,\n",
    "            \"output_indices\": outputs,\n",
    "            \"output_names\": getattr(self.model, \"output_names\", None)\n",
    "        }\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"shap.explainers.PartitionExplainer()\"\n",
    "\n",
    "\n",
    "    ################\n",
    "    # owen3 has a more efficient strategy dynamically adjusting the context and the number of evaluations\n",
    "    # I removed it for now to understand the method\n",
    "    ###############\n",
    "\n",
    "\n",
    "    def owen(self, fm, f00, f11, max_evals, output_indexes, fixed_context, batch_size, silent):\n",
    "        \"\"\"Compute a nested set of recursive Owen values based on an ordering recursion.\"\"\"\n",
    "        #f = self._reshaped_model\n",
    "        #r = self.masker\n",
    "        #masks = np.zeros(2*len(inds)+1, dtype=int)\n",
    "        M = len(fm)\n",
    "        m00 = np.zeros(M, dtype=bool)        #f00 = fm(m00.reshape(1,-1))[0] = fm(m00.reshape(1, -1), zero_index=0)[0]\n",
    "        base_value = f00\n",
    "        #f11 = fm(~m00.reshape(1,-1))[0]\n",
    "        #f11 = self._reshaped_model(r(~m00, x)).mean(0)\n",
    "        ind = len(self.dvalues)-1 # index the length of the hierarchy\n",
    "\n",
    "        # make sure output_indexes is a list of indexes\n",
    "        if output_indexes is not None:\n",
    "            # assert self.multi_output, \"output_indexes is only valid for multi-output models!\"\n",
    "            # inds = output_indexes.apply(f11, 0)\n",
    "            # out_len = output_indexes_len(output_indexes)\n",
    "            # if output_indexes.startswith(\"max(\"):\n",
    "            #     output_indexes = np.argsort(-f11)[:out_len]\n",
    "            # elif output_indexes.startswith(\"min(\"):\n",
    "            #     output_indexes = np.argsort(f11)[:out_len]\n",
    "            # elif output_indexes.startswith(\"max(abs(\"):\n",
    "            #     output_indexes = np.argsort(np.abs(f11))[:out_len]\n",
    "            print(output_indexes) # for this one is none\n",
    "\n",
    "            f00 = f00[output_indexes]\n",
    "            f11 = f11[output_indexes]\n",
    "\n",
    "        q = queue.PriorityQueue() # setting up priority que\n",
    "        q.put((0, 0, (m00, f00, f11, ind, 1.0))) # the things in the cue are the all false array, all false value, all true value, length of hierarchy, weight??\n",
    "        eval_count = 0\n",
    "        total_evals = min(max_evals, (M-1)*M) # TODO: (M-1)*M is only right for balanced clusterings, but this is just for plotting progress...\n",
    "        pbar = None\n",
    "        start_time = time.time()\n",
    "        while not q.empty(): #################### go throught the whole que ##############################\n",
    "            \n",
    "\n",
    "            # if we passed our execution limit then leave everything else on the internal nodes\n",
    "            if eval_count >= max_evals:\n",
    "                print(\"we are doing this\")\n",
    "                while not q.empty():\n",
    "                    m00, f00, f11, ind, weight = q.get()[2]\n",
    "                    self.dvalues[ind] += (f11 - f00) * weight\n",
    "                break\n",
    "\n",
    "            # create a batch of work to do\n",
    "            batch_args = []\n",
    "            batch_masks = [] # batch size is 10 at auto\n",
    "            while not q.empty() and len(batch_masks) < batch_size and eval_count + len(batch_masks) < max_evals:\n",
    "                # work until q is not empty or other stop criterion are triggered\n",
    "\n",
    "                # get our next set of arguments\n",
    "                m00, f00, f11, ind, weight = q.get()[2]\n",
    "\n",
    "                # get the left and right children of this cluster\n",
    "                lind = int(self._clustering[ind-M, 0]) if ind >= M else -1\n",
    "                rind = int(self._clustering[ind-M, 1]) if ind >= M else -1\n",
    "\n",
    "                # get the distance of this cluster's children\n",
    "                if ind < M:\n",
    "                    distance = -1\n",
    "                else:\n",
    "                    if self._clustering.shape[1] >= 3:\n",
    "                        distance = self._clustering[ind-M, 2]\n",
    "                    else:\n",
    "                        distance = 1\n",
    "\n",
    "                # check if we are a leaf node (or other negative distance cluster) and so should terminate our decent\n",
    "                if distance < 0:\n",
    "                    self.dvalues[ind] += (f11 - f00) * weight\n",
    "                    continue\n",
    "\n",
    "                # build the masks\n",
    "                #print(self._clustering)\n",
    "                m10 = m00.copy() # we separate the copy from the add so as to not get converted to a matrix\n",
    "                m10[:] += self._mask_matrix[lind, :]\n",
    "                #print(self._mask_matrix)\n",
    "                #print(m10)\n",
    "                m01 = m00.copy()\n",
    "                m01[:] += self._mask_matrix[rind, :]\n",
    "                #print(m01)\n",
    "\n",
    "                batch_args.append((m00, m10, m01, f00, f11, ind, lind, rind, weight))\n",
    "                batch_masks.append(m10)\n",
    "                batch_masks.append(m01)\n",
    "\n",
    "\n",
    "            batch_masks = np.array(batch_masks)\n",
    "\n",
    "            # run the batch\n",
    "            if len(batch_args) > 0:\n",
    "                print(batch_masks)\n",
    "                fout = fm(batch_masks) # call to the model right here\n",
    "                if output_indexes is not None:\n",
    "                    fout = fout[:,output_indexes]\n",
    "\n",
    "                eval_count += len(batch_masks)\n",
    "\n",
    "                if pbar is None and time.time() - start_time > 5:\n",
    "                    pbar = tqdm(total=total_evals, disable=silent, leave=False)\n",
    "                    pbar.update(eval_count)\n",
    "                if pbar is not None:\n",
    "                    pbar.update(len(batch_masks))\n",
    "\n",
    "            # use the results of the batch to add new nodes\n",
    "            for i in range(len(batch_args)):\n",
    "\n",
    "                m00, m10, m01, f00, f11, ind, lind, rind, weight = batch_args[i]\n",
    "\n",
    "                # get the evaluated model output on the two new masked inputs\n",
    "                f10 = fout[2*i]\n",
    "                f01 = fout[2*i+1]\n",
    "\n",
    "                new_weight = weight\n",
    "                if fixed_context is None:\n",
    "                    new_weight /= 2\n",
    "                elif fixed_context == 0:\n",
    "                    self.dvalues[ind] += (f11 - f10 - f01 + f00) * weight # leave the interaction effect on the internal node\n",
    "                elif fixed_context == 1:\n",
    "                    self.dvalues[ind] -= (f11 - f10 - f01 + f00) * weight # leave the interaction effect on the internal node\n",
    "\n",
    "                if fixed_context is None or fixed_context == 0:\n",
    "                    # recurse on the left node with zero context\n",
    "                    args = (m00, f00, f10, lind, new_weight)\n",
    "                    q.put((-np.max(np.abs(f10 - f00)) * new_weight, np.random.randn(), args))\n",
    "\n",
    "                    # recurse on the right node with zero context\n",
    "                    args = (m00, f00, f01, rind, new_weight)\n",
    "                    q.put((-np.max(np.abs(f01 - f00)) * new_weight, np.random.randn(), args))\n",
    "\n",
    "                if fixed_context is None or fixed_context == 1:\n",
    "                    # recurse on the left node with one context\n",
    "                    args = (m01, f01, f11, lind, new_weight)\n",
    "                    q.put((-np.max(np.abs(f11 - f01)) * new_weight, np.random.randn(), args))\n",
    "\n",
    "                    # recurse on the right node with one context\n",
    "                    args = (m10, f10, f11, rind, new_weight)\n",
    "                    q.put((-np.max(np.abs(f11 - f10)) * new_weight, np.random.randn(), args))\n",
    "\n",
    "        if pbar is not None:\n",
    "            pbar.close()\n",
    "            \n",
    "        print(eval_count)\n",
    "\n",
    "        self.last_eval_count = eval_count\n",
    "\n",
    "        return output_indexes, base_value\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@njit\n",
    "def lower_credit(i, value, M, values, clustering):\n",
    "    if i < M: # M number of features, i\n",
    "        values[i] += value\n",
    "        return\n",
    "    li = int(clustering[i-M,0]) # get the left index of the top node\n",
    "    ri = int(clustering[i-M,1]) # get the right index of the top node\n",
    "    group_size = int(clustering[i-M,3]) # get the number of features in the top node\n",
    "    lsize = int(clustering[li-M,3]) if li >= M else 1 #\n",
    "    rsize = int(clustering[ri-M,3]) if ri >= M else 1\n",
    "    assert lsize+rsize == group_size\n",
    "    values[i] += value\n",
    "    lower_credit(li, values[i] * lsize / group_size, M, values, clustering)\n",
    "    lower_credit(ri, values[i] * rsize / group_size, M, values, clustering)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb44207-0fa4-4cbd-a298-cfbdd40a4efa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13f59ac7-5cdf-4a36-b6d7-c5d84a1641d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "X = [[i] for i in [2, 8, 0, 4, 1, 9, 9, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d045b898-9721-49ac-af78-77242c578967",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2], [8], [0], [4], [1], [9], [9], [0]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "613a1de6-2df2-43a2-8e07-fbbd757c09ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2500x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Z = linkage(X, 'single')\n",
    "\n",
    "fig = plt.figure(figsize=(25, 10))\n",
    "\n",
    "dn = dendrogram(Z)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c139f5c6-a03c-456b-a584-6f2de1afbed7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.,  7.,  0.,  2.],\n",
       "       [ 5.,  6.,  0.,  2.],\n",
       "       [ 0.,  4.,  1.,  2.],\n",
       "       [ 8., 10.,  1.,  4.],\n",
       "       [ 1.,  9.,  1.,  3.],\n",
       "       [ 3., 11.,  2.,  5.],\n",
       "       [12., 13.,  4.,  8.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b324e890-e5e7-4e4e-aa15-fd1fbbf66281",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
